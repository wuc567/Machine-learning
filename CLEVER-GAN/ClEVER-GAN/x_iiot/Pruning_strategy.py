import time
from copy import deepcopy

import pandas as pd
import numpy as np
import random
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter
from fvcore.nn import FlopCountAnalysis, parameter_count
from torch.optim.lr_scheduler import ReduceLROnPlateau


def set_seed(seed):
    torch.manual_seed(seed)  # ä¸ºCPUè®¾ç½®éšæœºç§å­
    torch.cuda.manual_seed(seed)  # ä¸ºå½“å‰GPUè®¾ç½®éšæœºç§å­
    torch.cuda.manual_seed_all(seed)  # å¦‚æœä½¿ç”¨å¤šä¸ªGPUï¼Œä¹Ÿè¦è®¾ç½®éšæœºç§å­
    np.random.seed(seed)  # è®¾ç½®numpyçš„éšæœºç§å­
    random.seed(seed)  # è®¾ç½®Pythonå†…ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„éšæœºç§å­
    torch.backends.cudnn.deterministic = True  # ç¡®ä¿å·ç§¯ç­‰æ“ä½œçš„ç»“æœç¡®å®š
    torch.backends.cudnn.benchmark = False  # ç¦ç”¨cudnnçš„è‡ªåŠ¨ä¼˜åŒ–ç®—æ³•é€‰æ‹©


set_seed(42)  # è®¾ç½®ä¸ºå›ºå®šçš„éšæœºç§å­ï¼Œä¾‹å¦‚42


def gen_loss_l1(masks, lambda_prune=1e-6):
    # å‰ªæåº¦é‡æŸå¤±å‡½æ•°ï¼ˆåŸºäº L1 æ­£åˆ™åŒ–ï¼‰
    loss = 0
    for mask in masks:
        loss += torch.sum(torch.abs(mask))  # L1 æ­£åˆ™åŒ–ï¼Œé¼“åŠ±ç¨€ç–æ€§
    return lambda_prune * loss


def calculate_accuracy(preds, labels):
    _, predicted = torch.max(preds, 1)
    correct = (predicted == labels).float()
    return correct.sum() / len(labels)


class MaskGenerator(nn.Module):
    def __init__(self, z_dim, weight_shapes):
        super(MaskGenerator, self).__init__()
        # ç”Ÿæˆå™¨çš„ä¸åŒå±‚ï¼Œè¾“å‡ºå¯¹åº”æƒé‡å½¢çŠ¶çš„æ©ç 
        self.fc1 = nn.Linear(z_dim, weight_shapes[0][0] * weight_shapes[0][1] * weight_shapes[0][2])  # å¯¹åº”æƒé‡ [1, 1, 3]
        self.fc2 = nn.Linear(z_dim, weight_shapes[1][0] * weight_shapes[1][1] * weight_shapes[1][2])  # å¯¹åº”æƒé‡ [16, 1, 1]
        self.fc3 = nn.Linear(z_dim, weight_shapes[2][0] * weight_shapes[2][1] * weight_shapes[2][2])  # å¯¹åº”æƒé‡ [16, 1, 3]
        self.fc4 = nn.Linear(z_dim, weight_shapes[3][0] * weight_shapes[3][1] * weight_shapes[3][2])  # å¯¹åº”æƒé‡ [32, 16, 1]
        self.fc5 = nn.Linear(z_dim, weight_shapes[4][0] * weight_shapes[4][1] * weight_shapes[4][2])  # å¯¹åº”æƒé‡ [32, 1, 3]
        self.fc6 = nn.Linear(z_dim, weight_shapes[5][0] * weight_shapes[5][1] * weight_shapes[5][2])  # å¯¹åº”æƒé‡ [64, 32, 1]
        self.fc7 = nn.Linear(z_dim, weight_shapes[6][0] * weight_shapes[6][1])  # å¯¹åº”æƒé‡ [100, 192]
        self.fc8 = nn.Linear(z_dim, weight_shapes[7][0] * weight_shapes[7][1])  # å¯¹åº”æƒé‡ [50, 100]
        self.fc9 = nn.Linear(z_dim, weight_shapes[8][0] * weight_shapes[8][1])  # å¯¹åº”æƒé‡ [20, 50]
        self.fc10 = nn.Linear(z_dim, weight_shapes[9][0] * weight_shapes[9][1])  # å¯¹åº”æƒé‡ [10, 20]

    def forward(self, z):
        # æ¯ä¸€å±‚ç”Ÿæˆå¯¹åº”å½¢çŠ¶çš„æ©ç 
        mask1 = torch.sigmoid(self.fc1(z)).view(weight_shapes[0][0], weight_shapes[0][1],
                                                weight_shapes[0][2])  # äºŒå€¼åŒ–å‰çš„è¿ç»­å€¼
        mask2 = torch.sigmoid(self.fc2(z)).view(weight_shapes[1][0], weight_shapes[1][1], weight_shapes[1][2])
        mask3 = torch.sigmoid(self.fc3(z)).view(weight_shapes[2][0], weight_shapes[2][1], weight_shapes[2][2])
        mask4 = torch.sigmoid(self.fc4(z)).view(weight_shapes[3][0], weight_shapes[3][1], weight_shapes[3][2])
        mask5 = torch.sigmoid(self.fc5(z)).view(weight_shapes[4][0], weight_shapes[4][1], weight_shapes[4][2])
        mask6 = torch.sigmoid(self.fc6(z)).view(weight_shapes[5][0], weight_shapes[5][1], weight_shapes[5][2])
        mask7 = torch.sigmoid(self.fc7(z)).view(weight_shapes[6][0], weight_shapes[6][1])
        mask8 = torch.sigmoid(self.fc8(z)).view(weight_shapes[7][0], weight_shapes[7][1])
        mask9 = torch.sigmoid(self.fc9(z)).view(weight_shapes[8][0], weight_shapes[8][1])
        mask10 = torch.sigmoid(self.fc10(z)).view(weight_shapes[9][0], weight_shapes[9][1])

        # å¯¹æ©ç è¿›è¡ŒäºŒå€¼åŒ–æ“ä½œï¼Œç”Ÿæˆ 0/1 æ©ç 
        # äºŒå€¼åŒ–å¤„ç†ï¼Œå¹¶ç”¨ detach ä¿æŒåå‘ä¼ æ’­èƒ½åŠ›
        mask1_binary = (mask1 > 0.5).float() + (mask1 - mask1.detach())
        mask2_binary = (mask2 > 0.5).float() + (mask2 - mask2.detach())
        mask3_binary = (mask3 > 0.5).float() + (mask3 - mask3.detach())
        mask4_binary = (mask4 > 0.5).float() + (mask4 - mask4.detach())
        mask5_binary = (mask5 > 0.5).float() + (mask5 - mask5.detach())
        mask6_binary = (mask6 > 0.5).float() + (mask6 - mask6.detach())
        mask7_binary = (mask7 > 0.5).float() + (mask7 - mask7.detach())
        mask8_binary = (mask8 > 0.5).float() + (mask8 - mask8.detach())
        mask9_binary = (mask9 > 0.5).float() + (mask9 - mask9.detach())
        mask10_binary = (mask10 > 0.5).float() + (mask10 - mask10.detach())

        return [mask1_binary, mask2_binary, mask3_binary, mask4_binary, mask5_binary, mask6_binary, mask7_binary,
                mask8_binary, mask9_binary, mask10_binary]


# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# data_generate = pd.read_csv('D:/python/pythonProject/PHDfirstTest/1000_vae_generated_data.csv', encoding='utf-8',
#                             low_memory=False)


data_generate = pd.read_csv(
    'D:/python/pythonProject/PHDfirstTest/x_iiot/x_iiot_1000_vae_gan_contra_lossMethod_generated_data.csv',
    encoding='utf-8',
    low_memory=False)

# data_generate = pd.read_csv('D:/python/pythonProject/PHDfirstTest/1000_vae_gan_contra_generated_data.csv', encoding='utf-8',
#                             low_memory=False)

# data_generate = pd.read_csv('D:/python/pythonProject/PHDfirstTest/1000_GAN_generated_data.csv', encoding='utf-8',
#                             low_memory=False)


data_generate = data_generate.to_numpy()

data = pd.read_csv('D:/python/pythonProject/PHDfirstTest/x_iiot/datasets_xiiot_afterProcess.csv', encoding='utf-8',
                   low_memory=False)

data = data.to_numpy()

# # æŒ‡å®šè¦æ£€æŸ¥çš„åˆ—ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰å’Œè¦åˆ é™¤çš„å€¼
# column_index = -2  # ç¬¬2åˆ—ï¼ˆç´¢å¼•ä¸º1ï¼‰
# value_to_remove = 9
#
# # ä½¿ç”¨å¸ƒå°”ç´¢å¼•æ¥ç­›é€‰å‡ºä¸åŒ…å«æŒ‡å®šå€¼çš„è¡Œ
# filtered_data = data[data[:, column_index] != value_to_remove]

# è®¡ç®—å€’æ•°ç¬¬ä¸€åˆ—å’Œå€’æ•°ç¬¬ä¸‰åˆ—çš„ç´¢å¼•
index_last = -1  # å€’æ•°ç¬¬ä¸€åˆ—
index_third_last = -3  # å€’æ•°ç¬¬ä¸‰åˆ—

# ä½¿ç”¨ numpy.delete() åˆ é™¤å€’æ•°ç¬¬ä¸€åˆ—å’Œå€’æ•°ç¬¬ä¸‰åˆ—
data = np.delete(data, [index_third_last, index_last], axis=1)

# åˆ›å»ºä¸€ä¸ªå…ƒç´ å…¨ä¸º9çš„æ–°åˆ—ï¼Œè¡Œæ•°ä¸åŸæ•°ç»„åŒ¹é…
new_column = np.full((data_generate.shape[0], 1), 9)

# ä½¿ç”¨ numpy.hstack() åœ¨åŸæ•°ç»„çš„å³ä¾§æ·»åŠ æ–°åˆ—
data_generate = np.hstack((data_generate, new_column))

#
# print(data.shape)
# print(data_generate.shape)


# çºµå‘æ‹¼æ¥
data_all = np.concatenate((data, data_generate), axis=0)

print(data.shape)
print(data_generate.shape)
print(data_all.shape)

feature = data_all[:, 0:-1]
lable = data_all[:, -1]

print(feature)
print(lable)

# åˆ’åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†

all_data = np.concatenate([feature, lable.reshape(-1, 1)], axis=1)

# è½¬åŒ–ä¸ºdataset
from torch.utils.data import DataLoader, Dataset
import torch
import numpy as np


class All_dataset(Dataset):
    def __init__(self):
        data = all_data
        self._x = torch.from_numpy(data[:, :-1])  # çº¿æ€§å›å½’å’ŒDNNä¸ç”¨å‡ç»´
        self.label = torch.from_numpy(data[:, -1])
        self.len = len(data)

    def __getitem__(self, item):
        return self._x[item], self.label[item]

    def __len__(self):
        return self.len


# all_dataset = All_dataset()
from torch.utils.data import random_split

dataset = All_dataset()  # åŸå§‹æ•°æ®é›†
train_ratio = 0.8  # è®­ç»ƒé›†çš„æ¯”ä¾‹ï¼Œä¾‹å¦‚å–80%
val_ratio = 0.1  # éªŒè¯é›†çš„æ¯”ä¾‹ï¼Œä¾‹å¦‚å–10%
test_ratio = 0.1  # æµ‹è¯•é›†çš„æ¯”ä¾‹ï¼Œä¾‹å¦‚å–10%

train_size = int(train_ratio * len(dataset))
val_size = int(val_ratio * len(dataset))
test_size = len(dataset) - train_size - val_size
train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

batch_size = 64

train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)

device = torch.device("cuda")
print(torch.cuda.is_available())

from MainModel import DepthwiseSeparableConv

# # æŸ¥çœ‹ç”Ÿæˆçš„æ©ç å½¢çŠ¶
# for mask in masks:
#     print(f"Generated mask shape: {mask.shape}")


# å®šä¹‰è¶…å‚æ•°
z_dim = 50
batch_size = 64
main_learning_rate = 0.001
generator_learning_rate = 0.000001
# generator_learning_rate = 0.001
num_epochs = 10
writer = SummaryWriter()

main_model = DepthwiseSeparableConv(batch_size).to(device)

# main_model = DepthwiseSeparableConv(batch_size)
criterion = nn.CrossEntropyLoss()
main_model_optimizer = optim.Adam(main_model.parameters(), lr=main_learning_rate)

# è·å–æƒé‡çš„å½¢çŠ¶åˆ—è¡¨
weight_shapes = [param.shape for name, param in main_model.named_parameters() if 'weight' in name]
print(weight_shapes)

generator = MaskGenerator(z_dim, weight_shapes).to(device)
# generator = MaskGenerator(z_dim, weight_shapes)
generator_optimizer = optim.Adam(generator.parameters(), lr=generator_learning_rate)


# # åˆå§‹åŒ–ç”Ÿæˆå™¨ï¼Œç”Ÿæˆä¸æƒé‡å½¢çŠ¶ç›¸åŒ¹é…çš„æ©ç 
# noise = torch.randn(1, z_dim)  # å‡è®¾å™ªå£°å‘é‡å¤§å°ä¸º 50
# mask_generator = MaskGenerator(z_dim, weight_shapes)
# masks = mask_generator(noise)
# è®­ç»ƒæ¨¡å‹

# --------------------------------------------------------------------------------------------------------------------------------
# è®¡ç®—å‚æ•°é‡
# åˆ›å»ºè¾“å…¥å¼ é‡
# input_tensor = torch.randn(64, 1, 57).to(device)
# input_tensor = torch.randn(64, 1, 57)
#
# # è®¡ç®— FLOPs
# flop_analysis = FlopCountAnalysis(main_model, input_tensor)
# flops = flop_analysis.total()
#
# # è®¡ç®—å‚æ•°é‡
# params = parameter_count(main_model)[""]
#
# print(f"FLOPs: {flops}")
# print(f"Params: {params}")
# æ‰“å°åŸå§‹æ¨¡å‹å‚æ•°æ•°é‡
def count_params(model):
    return sum(p.numel() for p in model.parameters())


print(f"Original parameter count: {count_params(main_model)}")

# --------------------------------------------------------------------------------------------------------------------------------

scheduler = ReduceLROnPlateau(generator_optimizer, mode='min', factor=0.1, patience=2)

main_model.train()  # è®¾ç½®ğŸ–æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
generator.train()

# åˆå§‹åŒ– L1 æŸå¤±æƒé‡ç³»æ•°
lambda_l1 = 1.0
prev_model_loss = float('inf')  # è®°å½•å‰ä¸€ä¸ª epoch çš„ä¸»æ¨¡å‹æŸå¤±
patience = 2  # è®¾å®šä¸€ä¸ªè€å¿ƒå€¼ï¼Œå…è®¸åœ¨å‡ ä¸ª epoch å†…æ¨¡å‹æŸå¤±æœ‰å°å¹…æ³¢åŠ¨
alpha = 1.0

for epoch in range(num_epochs):
    train_loss = 0.0
    train_correct = 0.0

    for batch_idx, (data, target) in enumerate(train_loader):
        # å°†æ•°æ®åŠ è½½åˆ°è®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰
        data, target = data.to(device), target.to(device)
        # data, target = data, target
        data = data.reshape(-1, 1, 57)
        data = data.float()  # å°†æ•°æ®ç±»å‹è½¬æ¢ä¸º float32
        # print(data.shape)
        target = target.long()

        # --------------------------------------------------è®­ç»ƒä¸»æ¨¡å‹ï¼ˆä½¿ç”¨ç”Ÿæˆå™¨ç”Ÿæˆæ©ç å¹¶ä¼ å…¥ä¸»æ¨¡å‹ï¼‰-----------------------------------------------------------------

        noise = torch.ones(1, z_dim).to(device)  # å‡è®¾å™ªå£°å‘é‡å¤§å°ä¸º 50
        # noise = torch.ones(1, z_dim)  # å‡è®¾å™ªå£°å‘é‡å¤§å°ä¸º 50
        masks = generator(noise)

        # åº”ç”¨æ©ç 
        with torch.no_grad():
            main_model.depthwise1.weight *= masks[0]
            main_model.pointwise1.weight *= masks[1]
            main_model.depthwise2.weight *= masks[2]
            main_model.pointwise2.weight *= masks[3]
            main_model.depthwise3.weight *= masks[4]
            main_model.pointwise3.weight *= masks[5]
            main_model.fc1.weight *= masks[6]
            main_model.fc2.weight *= masks[7]
            main_model.fc3.weight *= masks[8]
            main_model.fc4.weight *= masks[9]

        output = main_model(data)
        main_model_loss = criterion(output, target)
        main_model_optimizer.zero_grad()
        # main_model_loss.backward(retain_graph=True)
        main_model_loss.backward()
        main_model_optimizer.step()

        # main_model_optimizer.zero_grad()
        # main_model_loss.backward()
        # main_model_optimizer.step()

        # train_loss += main_model_loss.item()
        # train_correct += calculate_accuracy(output, target) * len(target)
        # -----------------------------------------------------------------------------------------------------------------------------------------------------------

        # -------------------------------------------------------------------------è®­ç»ƒç”Ÿæˆå™¨--------------------------------------------------------------------------
        # generator_loss = lambda_l1 * gen_loss_l1(masks) + alpha * main_model_loss
        # generator_optimizer.zero_grad()
        # generator_loss.backward()
        # generator_optimizer.step()

        generator_loss = gen_loss_l1(masks)
        generator_optimizer.zero_grad()
        generator_loss.backward()
        generator_optimizer.step()

        # -----------------------------------------------------------------------------------------------------------------------------------------------------------

        train_loss += main_model_loss.item()
        train_correct += calculate_accuracy(output, target) * len(target)

    avg_train_loss = train_loss / len(train_loader)
    avg_train_acc = train_correct / len(train_loader.dataset)

    # # è‡ªé€‚åº”è°ƒæ•´ L1 æŸå¤±æƒé‡
    # if avg_train_loss > prev_model_loss:
    #     patience = patience - 1
    #     if patience == 0:
    #         print("ä¸‹é™äº†")
    #         lambda_l1 = lambda_l1 * 0.5  # å‡å° L1 æ­£åˆ™åŒ–æƒé‡
    #         # alpha = alpha * 2
    #         patience = 2  # é‡ç½®è€å¿ƒå€¼
    # else:
    #     patience = 2  # é‡ç½®è€å¿ƒå€¼ï¼Œå¦‚æœæ¨¡å‹æ€§èƒ½æ²¡æœ‰ä¸‹é™

    prev_model_loss = avg_train_loss  # è®°å½•å½“å‰æ¨¡å‹çš„æŸå¤±

    # åœ¨æ¯ä¸ª epoch ä¸­ï¼Œè®°å½•è®­ç»ƒçš„æŸå¤±å’Œå‡†ç¡®ç‡
    writer.add_scalar('Loss/train', avg_train_loss, epoch)
    writer.add_scalar('Accuracy/train', avg_train_acc, epoch)

    scheduler.step(avg_train_loss)
    # è·å–å½“å‰å­¦ä¹ ç‡
    current_lr = scheduler.get_last_lr()[0]

    # æ‰“å°æ¯ä¸ª epoch ç»“æŸæ—¶çš„æŸå¤±
    # æ‰“å°è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±
    print(
        f"Epoch [{epoch + 1}/{num_epochs}], generator Loss: {generator_loss.item():.4f}, model Loss: {main_model_loss.item():.4f}, model Accuracy: {avg_train_acc:.4f}, generator learning rate:{current_lr:.20f}")

# --------------------------------------------------------------------------------------è®­ç»ƒç»“æŸ-----------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------æµ‹è¯•é˜¶æ®µ-----------------------------------------------------------------------------------


from sklearn.metrics import classification_report

generator.eval()
main_model.eval()
# ä½¿ç”¨è®­ç»ƒå¥½çš„ç”Ÿæˆå™¨ç”Ÿæˆæ©ç 
z = torch.ones(1, z_dim).to(device)  # ç”Ÿæˆéšæœºå™ªå£°
# z = torch.ones(1, z_dim)  # ç”Ÿæˆéšæœºå™ªå£°
masks = generator(z)
print(masks)

original_model = deepcopy(main_model)

# åº”ç”¨æ©ç 
with torch.no_grad():
    main_model.depthwise1.weight *= masks[0]
    main_model.pointwise1.weight *= masks[1]
    main_model.depthwise2.weight *= masks[2]
    main_model.pointwise2.weight *= masks[3]
    main_model.depthwise3.weight *= masks[4]
    main_model.pointwise3.weight *= masks[5]
    main_model.fc1.weight *= masks[6]
    main_model.fc2.weight *= masks[7]
    main_model.fc3.weight *= masks[8]
    main_model.fc4.weight *= masks[9]

pruned_model = deepcopy(main_model)

# nonzero_params_before = sum(p.numel() for p in original_model.parameters() if p.data.nonzero().numel() > 0)
# print(f"å‰ªæå‰éé›¶å‚æ•°æ•°é‡: {nonzero_params_before}")
# nonzero_params_after = sum(p.numel() for p in pruned_model.parameters() if p.data.nonzero().numel() > 0)
# print(f"å‰ªæåéé›¶å‚æ•°æ•°é‡: {nonzero_params_after}")




# --------------------------------------------------------------------------------------------------------------------------------
# æ‰“å°æ¨¡å‹çš„éé›¶å‚æ•°æ•°é‡ï¼ˆå‰ªæåçš„æœ‰æ•ˆå‚æ•°ï¼‰
def count_nonzero_parameters(model):
    total_nonzero_params = sum((p != 0).sum().item() for p in model.parameters() if p.requires_grad)
    return total_nonzero_params


# è®¡ç®—æ¨¡å‹æ¨ç†æ—¶é—´
def measure_inference_time(model, input_size, device='cpu', iterations=100):
    model.eval()
    x = torch.randn(input_size).to(device)

    # æµ‹é‡æ—¶é—´
    start_time = time.time()
    with torch.no_grad():
        for _ in range(iterations):
            _ = model(x)
    end_time = time.time()

    avg_time = (end_time - start_time) / iterations
    return avg_time


# æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡
def count_parameters(model):
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params


# æµ‹è¯•æ¨¡å‹çš„å‰ªææ•ˆæœ
def test_pruned_model(original_model, pruned_model, input_size, device='cpu'):
    original_model.to(device)
    pruned_model.to(device)

    # ç»Ÿè®¡å‚æ•°æ•°é‡
    print(f"åŸå§‹æ¨¡å‹å‚æ•°æ•°é‡: {count_parameters(original_model)}")
    print(f"å‰ªæåæ¨¡å‹å‚æ•°æ•°é‡: {count_parameters(pruned_model)}")

    # ç»Ÿè®¡éé›¶å‚æ•°æ•°é‡
    print(f"åŸå§‹æ¨¡å‹éé›¶å‚æ•°æ•°é‡: {count_nonzero_parameters(original_model)}")
    print(f"å‰ªæåæ¨¡å‹éé›¶å‚æ•°æ•°é‡: {count_nonzero_parameters(pruned_model)}")

    # æµ‹é‡æ¨ç†æ—¶é—´
    original_time = measure_inference_time(original_model, input_size, device=device)
    pruned_time = measure_inference_time(pruned_model, input_size, device=device)

    print(f"åŸå§‹æ¨¡å‹å¹³å‡æ¨ç†æ—¶é—´: {original_time:.6f} ç§’")
    print(f"å‰ªæåæ¨¡å‹å¹³å‡æ¨ç†æ—¶é—´: {pruned_time:.6f} ç§’")


test_pruned_model(original_model, pruned_model, (64, 1, 57), 'cuda')

import torch
import torchprofile

# å‡è®¾ main_model æ˜¯ä½ çš„æ¨¡å‹
dummy_input = torch.randn(64, 1, 57).to(device)  # æ ¹æ®ä½ çš„è¾“å…¥å½¢çŠ¶è¿›è¡Œè°ƒæ•´
flops_original = torchprofile.profile_macs(original_model, dummy_input)
flops_pruned = torchprofile.profile_macs(pruned_model, dummy_input)

print(f"åŸå§‹æ¨¡å‹FLOPs: {flops_original}")
print(f"å‰ªæåæ¨¡å‹FLOPs: {flops_pruned}")

# --------------------------------------------------------------------------------------------------------------------------------

all_preds = []
all_labels = []
correct = 0
total = 0

class_names = ['Normal', 'C&C', 'Exfiltration', 'Exploitation', 'Lateral _movement', 'RDOS', 'Reconnaissance',
               'Tampering', 'Weaponization', 'crypto-ransomware']

with torch.no_grad():
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        # data, target = data, target
        data = data.reshape(-1, 1, 57)
        data = data.float()  # å°†æ•°æ®ç±»å‹è½¬æ¢ä¸º float32
        target = target.long()

        # outputs = main_model(data)
        outputs = pruned_model(data)

        _, predicted = torch.max(outputs.data, 1)
        total += target.size(0)
        correct += (predicted == target).sum().item()

        all_preds.extend(predicted.cpu().numpy())  # å°†GPUä¸Šçš„å¼ é‡ç§»å›CPU
        all_labels.extend(target.cpu().numpy())

print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')
# ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
print(classification_report(all_labels, all_preds, target_names=class_names))

# class PrunedModel(nn.Module):
#     def __init__(self, original_model, mask):
#         super(PrunedModel, self).__init__()
#
#         # æ ¹æ®æ©ç è¿‡æ»¤æœ‰æ•ˆçš„é€šé“
#         keep_channels = mask[0].squeeze().nonzero(as_tuple=True)[0].tolist()
#         in_channels = original_model.depthwise1.in_channels
#         out_channels = len(keep_channels)
#         self.depthwise1 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1,
#                                     padding=1,
#                                     groups=1, bias=False)
#
#         keep_channels = mask[1].squeeze().nonzero(as_tuple=True)[0].tolist()
#         in_channels = original_model.pointwise1.in_channels
#         out_channels = len(keep_channels)
#         self.pointwise1 = nn.Conv1d(in_channels, out_channels, kernel_size=1,
#                                     stride=1, padding=0, bias=False)
#
#         keep_channels = mask[2].squeeze().nonzero(as_tuple=True)[0].tolist()
#         in_channels = original_model.depthwise2.in_channels
#         out_channels = len(keep_channels)
#         self.depthwise2 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1,
#                                     padding=1,
#                                     groups=1, bias=False)
#
#         keep_channels = mask[3].squeeze().nonzero(as_tuple=True)[0].tolist()
#         in_channels = original_model.pointwise2.in_channels
#         out_channels = len(keep_channels)
#         self.pointwise2 = nn.Conv1d(in_channels, out_channels, kernel_size=1,
#                                     stride=1, padding=0, bias=False)
#
#         keep_channels = mask[4].squeeze().nonzero(as_tuple=True)[0].tolist()
#         in_channels = original_model.depthwise3.in_channels
#         out_channels = len(keep_channels)
#         self.depthwise3 = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1,
#                                     padding=1,
#                                     groups=1, bias=False)
#
#         keep_channels = mask[5].squeeze().nonzero(as_tuple=True)[0].tolist()
#         in_channels = original_model.pointwise3.in_channels
#         out_channels = len(keep_channels)
#         self.pointwise3 = nn.Conv1d(in_channels, out_channels, kernel_size=1,
#                                     stride=1, padding=0, bias=False)
#
#         # å¤„ç†å…¨è¿æ¥å±‚
#         keep_channels_fc1 = masks[6].squeeze().nonzero(as_tuple=True)[0].tolist()
#         self.fc1 = nn.Linear(
#             in_features=len(keep_channels_fc1),
#             out_features=original_model.fc1.out_features
#         )
#
#         keep_channels_fc2 = masks[7].squeeze().nonzero(as_tuple=True)[0].tolist()
#         self.fc2 = nn.Linear(
#             in_features=len(keep_channels_fc2),
#             out_features=original_model.fc2.out_features
#         )
#
#         keep_channels_fc3 = masks[8].squeeze().nonzero(as_tuple=True)[0].tolist()
#         self.fc3 = nn.Linear(
#             in_features=len(keep_channels_fc3),
#             out_features=original_model.fc3.out_features
#         )
#
#         keep_channels_fc4 = masks[9].squeeze().nonzero(as_tuple=True)[0].tolist()
#         self.fc4 = nn.Linear(
#             in_features=len(keep_channels_fc4),
#             out_features=original_model.fc4.out_features
#         )
#
#     def forward(self, x):
#         # é€šè¿‡æ·±åº¦å·ç§¯å±‚
#         out = self.depthwise1(x)
#         print(out.shape)
#         # é€šè¿‡é€ç‚¹å·ç§¯å±‚
#         out = self.pointwise1(out)
#         out = F.relu(out)
#         out = F.max_pool1d(out, 2)
#         print(out.shape)
#
#         # é€šè¿‡æ·±åº¦å·ç§¯å±‚
#         out = self.depthwise2(out)
#         # é€šè¿‡é€ç‚¹å·ç§¯å±‚
#         out = self.pointwise2(out)
#         out = F.relu(out)
#         out = F.max_pool1d(out, 3)
#
#         # é€šè¿‡æ·±åº¦å·ç§¯å±‚
#         out = self.depthwise3(out)
#         # é€šè¿‡é€ç‚¹å·ç§¯å±‚
#         out = self.pointwise3(out)
#         out = F.relu(out)
#         out = F.max_pool1d(out, 3)
#         # print("å½¢çŠ¶ä¸ºï¼š", out.shape)
#         out = out.reshape(self.batch_size, -1)
#
#         out = F.relu(self.fc1(out))
#         out = F.relu(self.fc2(out))
#         out = F.relu(self.fc3(out))
#         out = self.fc4(out)
#
#         return out
#
#
# def copy_pruned_weights(original_model, pruned_model, mask):
#     with torch.no_grad():
#         # è·å–éœ€è¦ä¿ç•™çš„é€šé“ç´¢å¼•
#         keep_channels = mask[0].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.depthwise1.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.depthwise1.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[1].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.pointwise1.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.pointwise1.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[2].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.depthwise2.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.depthwise2.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[3].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.pointwise2.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.pointwise2.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[4].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.depthwise3.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.depthwise3.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[5].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.pointwise3.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.pointwise3.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[6].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.fc1.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.fc1.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[7].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.fc2.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.fc2.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[8].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.fc3.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.fc3.weight.data[:len(keep_channels)] = pruned_weights
#
#         keep_channels = mask[9].squeeze().nonzero(as_tuple=True)[0].tolist()
#         # å‰ªåˆ‡åŸå§‹æ¨¡å‹çš„æƒé‡
#         original_weights = original_model.fc4.weight.data
#         pruned_weights = original_weights[keep_channels]
#         # èµ‹å€¼åˆ°æ–°æ¨¡å‹çš„æƒé‡
#         pruned_model.fc4.weight.data[:len(keep_channels)] = pruned_weights


# å¤åˆ¶å‰ªæåçš„æƒé‡
# copy_pruned_weights(main_model, pruned_model, masks)
