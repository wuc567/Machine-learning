import os
import time
from copy import deepcopy
import torchprofile
import pandas as pd
import numpy as np
import random
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.tensorboard import SummaryWriter
from fvcore.nn import FlopCountAnalysis, parameter_count
from torch.optim.lr_scheduler import ReduceLROnPlateau
import torch.nn.utils.prune as prune
from sklearn.metrics import classification_report


def set_seed(seed):
    torch.manual_seed(seed)  # ä¸ºCPUè®¾ç½®éšæœºç§å­
    torch.cuda.manual_seed(seed)  # ä¸ºå½“å‰GPUè®¾ç½®éšæœºç§å­
    torch.cuda.manual_seed_all(seed)  # å¦‚æœä½¿ç”¨å¤šä¸ªGPUï¼Œä¹Ÿè¦è®¾ç½®éšæœºç§å­
    np.random.seed(seed)  # è®¾ç½®numpyçš„éšæœºç§å­
    random.seed(seed)  # è®¾ç½®Pythonå†…ç½®éšæœºæ•°ç”Ÿæˆå™¨çš„éšæœºç§å­
    torch.backends.cudnn.deterministic = True  # ç¡®ä¿å·ç§¯ç­‰æ“ä½œçš„ç»“æœç¡®å®š
    torch.backends.cudnn.benchmark = False  # ç¦ç”¨cudnnçš„è‡ªåŠ¨ä¼˜åŒ–ç®—æ³•é€‰æ‹©


set_seed(42)  # è®¾ç½®ä¸ºå›ºå®šçš„éšæœºç§å­ï¼Œä¾‹å¦‚42


# ç”Ÿæˆå™¨ï¼Œç”¨äºç”Ÿæˆæ¯å±‚çš„è£å‰ªæ¯”ä¾‹
class PruningGenerator(nn.Module):
    def __init__(self, noise_dim, num_layers):
        super(PruningGenerator, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(noise_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, num_layers),
            nn.Sigmoid()  # ç”Ÿæˆ [0, 1] ä¹‹é—´çš„è£å‰ªæ¯”ä¾‹
        )

    def forward(self, z):
        return self.fc(z)


def gen_get_loss(amounts):
    # amounts_tensor = torch.tensor(amounts)
    # return -torch.log(1 + torch.sum(amounts))
    return torch.exp(-torch.sum(amounts))


def calculate_accuracy(preds, labels):
    _, predicted = torch.max(preds, 1)
    correct = (predicted == labels).float()
    return correct.sum() / len(labels)


# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# print(f"Using device: {device}")
# device = torch.device("cpu")

# data_generate = pd.read_csv('D:/python/pythonProject/PHDfirstTest/1000_vae_generated_data.csv', encoding='utf-8',
#                             low_memory=False)


data_generate = pd.read_csv(
    'D:/python/pythonProject/PHDfirstTest/x_iiot/x_iiot_1000_vae_gan_contra_lossMethod_generated_data.csv',
    encoding='utf-8',
    low_memory=False)

# data_generate = pd.read_csv('D:/python/pythonProject/PHDfirstTest/1000_vae_gan_contra_generated_data.csv', encoding='utf-8',
#                             low_memory=False)

# data_generate = pd.read_csv('D:/python/pythonProject/PHDfirstTest/1000_GAN_generated_data.csv', encoding='utf-8',
#                             low_memory=False)


data_generate = data_generate.to_numpy()

data = pd.read_csv('D:/python/pythonProject/PHDfirstTest/x_iiot/datasets_xiiot_afterProcess.csv', encoding='utf-8',
                   low_memory=False)

data = data.to_numpy()

# # æŒ‡å®šè¦æ£€æŸ¥çš„åˆ—ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰å’Œè¦åˆ é™¤çš„å€¼
# column_index = -2  # ç¬¬2åˆ—ï¼ˆç´¢å¼•ä¸º1ï¼‰
# value_to_remove = 9
#
# # ä½¿ç”¨å¸ƒå°”ç´¢å¼•æ¥ç­›é€‰å‡ºä¸åŒ…å«æŒ‡å®šå€¼çš„è¡Œ
# filtered_data = data[data[:, column_index] != value_to_remove]

# è®¡ç®—å€’æ•°ç¬¬ä¸€åˆ—å’Œå€’æ•°ç¬¬ä¸‰åˆ—çš„ç´¢å¼•
index_last = -1  # å€’æ•°ç¬¬ä¸€åˆ—
index_third_last = -3  # å€’æ•°ç¬¬ä¸‰åˆ—

# ä½¿ç”¨ numpy.delete() åˆ é™¤å€’æ•°ç¬¬ä¸€åˆ—å’Œå€’æ•°ç¬¬ä¸‰åˆ—
data = np.delete(data, [index_third_last, index_last], axis=1)

# åˆ›å»ºä¸€ä¸ªå…ƒç´ å…¨ä¸º9çš„æ–°åˆ—ï¼Œè¡Œæ•°ä¸åŸæ•°ç»„åŒ¹é…
new_column = np.full((data_generate.shape[0], 1), 9)

# ä½¿ç”¨ numpy.hstack() åœ¨åŸæ•°ç»„çš„å³ä¾§æ·»åŠ æ–°åˆ—
data_generate = np.hstack((data_generate, new_column))

#
# print(data.shape)
# print(data_generate.shape)


# çºµå‘æ‹¼æ¥
data_all = np.concatenate((data, data_generate), axis=0)

print(data.shape)
print(data_generate.shape)
print(data_all.shape)

feature = data_all[:, 0:-1]
lable = data_all[:, -1]

print(feature)
print(lable)

# åˆ’åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†

all_data = np.concatenate([feature, lable.reshape(-1, 1)], axis=1)

# è½¬åŒ–ä¸ºdataset
from torch.utils.data import DataLoader, Dataset
import torch
import numpy as np


class All_dataset(Dataset):
    def __init__(self):
        data = all_data
        self._x = torch.from_numpy(data[:, :-1])  # çº¿æ€§å›å½’å’ŒDNNä¸ç”¨å‡ç»´
        self.label = torch.from_numpy(data[:, -1])
        self.len = len(data)

    def __getitem__(self, item):
        return self._x[item], self.label[item]

    def __len__(self):
        return self.len


# all_dataset = All_dataset()
from torch.utils.data import random_split

dataset = All_dataset()  # åŸå§‹æ•°æ®é›†
train_ratio = 0.8  # è®­ç»ƒé›†çš„æ¯”ä¾‹ï¼Œä¾‹å¦‚å–80%
val_ratio = 0.1  # éªŒè¯é›†çš„æ¯”ä¾‹ï¼Œä¾‹å¦‚å–10%
test_ratio = 0.1  # æµ‹è¯•é›†çš„æ¯”ä¾‹ï¼Œä¾‹å¦‚å–10%

train_size = int(train_ratio * len(dataset))
val_size = int(val_ratio * len(dataset))
test_size = len(dataset) - train_size - val_size
train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])

batch_size = 64

train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)

print(torch.cuda.is_available())

from MainModel import DepthwiseSeparableConv

# # æŸ¥çœ‹ç”Ÿæˆçš„æ©ç å½¢çŠ¶
# for mask in masks:
#     print(f"Generated mask shape: {mask.shape}")


# å®šä¹‰è¶…å‚æ•°
z_dim = 50
batch_size = 64
main_learning_rate = 0.001
generator_learning_rate = 0.000001
num_epochs = 10
writer = SummaryWriter()

main_model = DepthwiseSeparableConv(batch_size).to(device)

# main_model = DepthwiseSeparableConv(batch_size)
criterion = nn.CrossEntropyLoss()
main_model_optimizer = optim.Adam(main_model.parameters(), lr=main_learning_rate)

noise_dim = 50
num_layers = 10
generator = PruningGenerator(noise_dim, num_layers).to(device)
generator_optimizer = optim.Adam(generator.parameters(), lr=generator_learning_rate)

scheduler = ReduceLROnPlateau(generator_optimizer, mode='min', factor=0.1, patience=2)

main_model.train()  # è®¾ç½®ğŸ–æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
generator.train()

# --------------------------------------------------------------------------------------è®­ç»ƒå¼€å§‹-------------------------------------------------------------------------------------------

for epoch in range(num_epochs):
    train_loss = 0.0
    train_correct = 0.0

    for batch_idx, (data, target) in enumerate(train_loader):
        # å°†æ•°æ®åŠ è½½åˆ°è®¾å¤‡ï¼ˆGPUæˆ–CPUï¼‰
        data, target = data.to(device), target.to(device)
        data = data.reshape(-1, 1, 57)
        data = data.float()  # å°†æ•°æ®ç±»å‹è½¬æ¢ä¸º float32
        target = target.long()

        # --------------------------------------------------è®­ç»ƒä¸»æ¨¡å‹ï¼ˆä½¿ç”¨ç”Ÿæˆå™¨ç”Ÿæˆæ©ç å¹¶ä¼ å…¥ä¸»æ¨¡å‹ï¼‰-----------------------------------------------------------------

        # noise = torch.ones(1, z_dim).to(device)  # å‡è®¾å™ªå£°å‘é‡å¤§å°ä¸º 50
        noise = torch.randn(1, z_dim).to(device)  # å‡è®¾å™ªå£°å‘é‡å¤§å°ä¸º 50
        amounts = generator(noise)
        amounts2 = amounts.squeeze().tolist()

        with torch.no_grad():
            prune.l1_unstructured(main_model.depthwise1, name='weight', amount=amounts2[0])
            prune.l1_unstructured(main_model.pointwise1, name='weight', amount=amounts2[1])
            prune.l1_unstructured(main_model.depthwise2, name='weight', amount=amounts2[2])
            prune.l1_unstructured(main_model.pointwise2, name='weight', amount=amounts2[3])
            prune.l1_unstructured(main_model.depthwise3, name='weight', amount=amounts2[4])
            prune.l1_unstructured(main_model.pointwise3, name='weight', amount=amounts2[5])
            prune.l1_unstructured(main_model.fc1, name='weight', amount=amounts2[6])
            prune.l1_unstructured(main_model.fc2, name='weight', amount=amounts2[7])
            prune.l1_unstructured(main_model.fc3, name='weight', amount=amounts2[8])
            prune.l1_unstructured(main_model.fc4, name='weight', amount=amounts2[9])

        # ç§»é™¤å·²ç»è¢«è£å‰ªçš„æƒé‡
        prune.remove(main_model.depthwise1, 'weight')
        prune.remove(main_model.pointwise1, 'weight')
        prune.remove(main_model.depthwise2, 'weight')
        prune.remove(main_model.pointwise2, 'weight')
        prune.remove(main_model.depthwise3, 'weight')
        prune.remove(main_model.pointwise3, 'weight')
        prune.remove(main_model.fc1, 'weight')
        prune.remove(main_model.fc2, 'weight')
        prune.remove(main_model.fc3, 'weight')
        prune.remove(main_model.fc4, 'weight')

        output = main_model(data)
        main_model_loss = criterion(output, target)
        main_model_optimizer.zero_grad()
        main_model_loss.backward()
        main_model_optimizer.step()

        # -----------------------------------------------------------------------------------------------------------------------------------------------------------

        # -------------------------------------------------------------------------è®­ç»ƒç”Ÿæˆå™¨--------------------------------------------------------------------------

        generator_loss = gen_get_loss(amounts)
        generator_optimizer.zero_grad()
        generator_loss.backward()
        generator_optimizer.step()

        # -----------------------------------------------------------------------------------------------------------------------------------------------------------

        train_loss += main_model_loss.item()
        train_correct += calculate_accuracy(output, target) * len(target)

    avg_train_loss = train_loss / len(train_loader)
    avg_train_acc = train_correct / len(train_loader.dataset)

    prev_model_loss = avg_train_loss  # è®°å½•å½“å‰æ¨¡å‹çš„æŸå¤±

    # åœ¨æ¯ä¸ª epoch ä¸­ï¼Œè®°å½•è®­ç»ƒçš„æŸå¤±å’Œå‡†ç¡®ç‡
    writer.add_scalar('Loss/train', avg_train_loss, epoch)
    writer.add_scalar('Accuracy/train', avg_train_acc, epoch)

    scheduler.step(avg_train_loss)
    # è·å–å½“å‰å­¦ä¹ ç‡
    current_lr = scheduler.get_last_lr()[0]
    # æ‰“å°æ¯ä¸ª epoch ç»“æŸæ—¶çš„æŸå¤±
    # æ‰“å°è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±
    print(
        f"Epoch [{epoch + 1}/{num_epochs}], generator Loss: {generator_loss.item():.4f}, model Loss: {main_model_loss.item():.4f}, model Accuracy: {avg_train_acc:.4f},generator learning rate:{current_lr:.20f}")


# --------------------------------------------------------------------------------------è®­ç»ƒç»“æŸ-----------------------------------------------------------------------------------

def count_nonzero_parameters(model):
    total_nonzero_params = sum((p != 0).sum().item() for p in model.parameters() if p.requires_grad)
    return total_nonzero_params


main_model.eval()
generator.eval()
# noise = torch.ones(1, z_dim).to(device)  # å‡è®¾å™ªå£°å‘é‡å¤§å°ä¸º 50
noise = torch.randn(1, z_dim).to(device)  # å‡è®¾å™ªå£°å‘é‡å¤§å°ä¸º 50
amounts_generator = generator(noise).squeeze().tolist()
print(amounts_generator)

original_model = deepcopy(main_model)

# print(f"å‰ªæå‰éé›¶å‚æ•°æ•°é‡: {count_nonzero_parameters(original_model)}")


with torch.no_grad():
    prune.l1_unstructured(main_model.depthwise1, name='weight', amount=amounts_generator[0])
    prune.l1_unstructured(main_model.pointwise1, name='weight', amount=amounts_generator[1])
    prune.l1_unstructured(main_model.depthwise2, name='weight', amount=amounts_generator[2])
    prune.l1_unstructured(main_model.pointwise2, name='weight', amount=amounts_generator[3])
    prune.l1_unstructured(main_model.depthwise3, name='weight', amount=amounts_generator[4])
    prune.l1_unstructured(main_model.pointwise3, name='weight', amount=amounts_generator[5])
    prune.l1_unstructured(main_model.fc1, name='weight', amount=amounts_generator[6])
    prune.l1_unstructured(main_model.fc2, name='weight', amount=amounts_generator[7])
    prune.l1_unstructured(main_model.fc3, name='weight', amount=amounts_generator[8])
    prune.l1_unstructured(main_model.fc4, name='weight', amount=amounts_generator[9])

# ç§»é™¤å·²ç»è¢«è£å‰ªçš„æƒé‡
prune.remove(main_model.depthwise1, 'weight')
prune.remove(main_model.pointwise1, 'weight')
prune.remove(main_model.depthwise2, 'weight')
prune.remove(main_model.pointwise2, 'weight')
prune.remove(main_model.depthwise3, 'weight')
prune.remove(main_model.pointwise3, 'weight')
prune.remove(main_model.fc1, 'weight')
prune.remove(main_model.fc2, 'weight')
prune.remove(main_model.fc3, 'weight')
prune.remove(main_model.fc4, 'weight')

pruned_model = deepcopy(main_model)

data = torch.randn(64, 1, 57).to(device)  # æ ¹æ®ä½ çš„æ•°æ®å½¢çŠ¶è°ƒæ•´
num = 10000

# æµ‹è¯•å‰ªæå‰æ¨¡å‹çš„é€Ÿåº¦
original_model.eval()
with torch.no_grad():
    start_time = time.time()
    for _ in range(num):  # é‡å¤æ‰§è¡Œnumæ¬¡ï¼Œå–å¹³å‡å€¼
        output = original_model(data)
    end_time = time.time()
    prune_time = (end_time - start_time) / num
    print(f"å‰ªæå‰æ¨¡å‹çš„å¹³å‡å‰å‘ä¼ æ’­æ—¶é—´: {prune_time:.6f} ç§’")

pruned_model.eval()
with torch.no_grad():
    start_time = time.time()
    for _ in range(num):
        output = pruned_model(data)
    end_time = time.time()
    post_prune_time = (end_time - start_time) / num
    print(f"å‰ªæåæ¨¡å‹çš„å¹³å‡å‰å‘ä¼ æ’­æ—¶é—´: {post_prune_time:.6f} ç§’")

print(f"å‰ªæå‰éé›¶å‚æ•°æ•°é‡: {count_nonzero_parameters(original_model)}")

print(f"å‰ªæåéé›¶å‚æ•°æ•°é‡: {count_nonzero_parameters(pruned_model)}")

total_params = sum(p.numel() for p in original_model.parameters() if p.requires_grad)
print(f"å‰ªæå‰æ€»å‚æ•°æ•°é‡: {total_params}")

total_params = sum(p.numel() for p in pruned_model.parameters() if p.requires_grad)
print(f"å‰ªæåæ€»å‚æ•°æ•°é‡: {total_params}")

dummy_input = torch.randn(64, 1, 57).to(device)  # æ ¹æ®ä½ çš„è¾“å…¥å½¢çŠ¶è¿›è¡Œè°ƒæ•´
flops1 = torchprofile.profile_macs(original_model, dummy_input)
print(f"åŸå§‹æ¨¡å‹FLOPs: {flops1}")

dummy_input = torch.randn(64, 1, 57).to(device)  # æ ¹æ®ä½ çš„è¾“å…¥å½¢çŠ¶è¿›è¡Œè°ƒæ•´
flops2 = torchprofile.profile_macs(pruned_model, dummy_input)
print(f"å‰ªæåæ¨¡å‹FLOPs: {flops2}")

all_preds = []
all_labels = []
correct = 0
total = 0

class_names = ['Normal', 'C&C', 'Exfiltration', 'Exploitation', 'Lateral _movement', 'RDOS', 'Reconnaissance',
               'Tampering', 'Weaponization', 'crypto-ransomware']

with torch.no_grad():
    for data, target in test_loader:
        data, target = data.to(device), target.to(device)
        # data, target = data, target
        data = data.reshape(-1, 1, 57)
        data = data.float()  # å°†æ•°æ®ç±»å‹è½¬æ¢ä¸º float32
        target = target.long()

        outputs = main_model(data)
        # outputs = pruned_model(data)

        _, predicted = torch.max(outputs.data, 1)
        total += target.size(0)
        correct += (predicted == target).sum().item()

        all_preds.extend(predicted.cpu().numpy())  # å°†GPUä¸Šçš„å¼ é‡ç§»å›CPU
        all_labels.extend(target.cpu().numpy())

print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')
# ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
print(classification_report(all_labels, all_preds, target_names=class_names))

# # ä¿å­˜å‰ªæå‰çš„æ¨¡å‹
# torch.save(original_model.state_dict(), 'x_iiot_main_model_before_pruning.pth')
#
# # å°†å‰ªæåæ¨¡å‹çš„å‚æ•°è½¬æ¢ä¸ºç¨€ç–æ ¼å¼å¹¶ä¿å­˜
# for name, param in pruned_model.named_parameters():
#     if param is not None:
#         pruned_model.state_dict()[name] = param.to_sparse()
#
# torch.save(pruned_model.state_dict(), 'x_iiot_pruned_model_sparse.pth')
#
# # æŸ¥çœ‹æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ä¸ºå•ä½ï¼‰
# before_size = os.path.getsize('x_iiot_main_model_before_pruning.pth')
# after_size = os.path.getsize('x_iiot_pruned_model_sparse.pth')
#
# print(f"å‰ªæå‰æ¨¡å‹æ–‡ä»¶å¤§å°: {before_size / (1024 * 1024):.2f} MB")
# print(f"å‰ªæåæ¨¡å‹æ–‡ä»¶å¤§å°: {after_size / (1024 * 1024):.2f} MB")


dense_weight1 = original_model.depthwise1.weight.data
dense_weight2 = original_model.pointwise1.weight.data
dense_weight3 = original_model.depthwise2.weight.data
dense_weight4 = original_model.pointwise2.weight.data
dense_weight5 = original_model.depthwise3.weight.data
dense_weight6 = original_model.pointwise3.weight.data
dense_weight7 = original_model.fc1.weight.data
dense_weight8 = original_model.fc2.weight.data
dense_weight9 = original_model.fc3.weight.data
dense_weight10 = original_model.fc4.weight.data
print(dense_weight1)
print(dense_weight2)
print(dense_weight3)

# è®¡ç®—éé›¶å…ƒç´ çš„æ•°é‡
non_zero_count1 = torch.count_nonzero(dense_weight1)
non_zero_count2 = torch.count_nonzero(dense_weight2)
non_zero_count3 = torch.count_nonzero(dense_weight3)
non_zero_count4 = torch.count_nonzero(dense_weight4)
non_zero_count5 = torch.count_nonzero(dense_weight5)
non_zero_count6 = torch.count_nonzero(dense_weight6)
non_zero_count7 = torch.count_nonzero(dense_weight7)
non_zero_count8 = torch.count_nonzero(dense_weight8)
non_zero_count9 = torch.count_nonzero(dense_weight9)
non_zero_count10 = torch.count_nonzero(dense_weight10)
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count1}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count2}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count3}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count4}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count5}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count6}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count7}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count8}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count9}")
print(f"å‰ªæå‰ç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count10}")


print(f"dense_weight1.nelement: {dense_weight1.nelement()}")
print(f"dense_weight2.nelement: {dense_weight2.nelement()}")
print(f"dense_weight3.nelement: {dense_weight3.nelement()}")

# è®¡ç®—å¯†é›†çŸ©é˜µçš„å­˜å‚¨ç©ºé—´
dense_size1 = dense_weight1.nelement() * dense_weight1.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size2 = dense_weight2.nelement() * dense_weight2.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size3 = dense_weight3.nelement() * dense_weight3.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
print(dense_size3)
dense_size4 = dense_weight4.nelement() * dense_weight4.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size5 = dense_weight5.nelement() * dense_weight5.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size6 = dense_weight6.nelement() * dense_weight6.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size7 = dense_weight7.nelement() * dense_weight7.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size8 = dense_weight8.nelement() * dense_weight8.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size9 = dense_weight9.nelement() * dense_weight9.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°
dense_size10 = dense_weight10.nelement() * dense_weight10.element_size()  # å…ƒç´ æ•°é‡ * æ¯ä¸ªå…ƒç´ çš„å­—èŠ‚æ•°

dense_size_all = dense_size1 + dense_size2 + dense_size3 + dense_size4 + dense_size5 + dense_size6 + dense_size7 + dense_size8 + dense_size9 + dense_size10
print(f"ç¨ å¯†çŸ©é˜µå ç”¨å­˜å‚¨ç©ºé—´: {dense_size_all / (1024 * 1024):.2f} MB")






dense_weight1 = pruned_model.depthwise1.weight.data
dense_weight2 = pruned_model.pointwise1.weight.data
dense_weight3 = pruned_model.depthwise2.weight.data
dense_weight4 = pruned_model.pointwise2.weight.data
dense_weight5 = pruned_model.depthwise3.weight.data
dense_weight6 = pruned_model.pointwise3.weight.data
dense_weight7 = pruned_model.fc1.weight.data
dense_weight8 = pruned_model.fc2.weight.data
dense_weight9 = pruned_model.fc3.weight.data
dense_weight10 = pruned_model.fc4.weight.data

print("-------------------------------------------------------------------------------------------------------------------------------------------------")
print(dense_weight1)
print(dense_weight2)
print(dense_weight3)
# è®¡ç®—éé›¶å…ƒç´ çš„æ•°é‡
non_zero_count1 = torch.count_nonzero(dense_weight1)
non_zero_count2 = torch.count_nonzero(dense_weight2)
non_zero_count3 = torch.count_nonzero(dense_weight3)
non_zero_count4 = torch.count_nonzero(dense_weight4)
non_zero_count5 = torch.count_nonzero(dense_weight5)
non_zero_count6 = torch.count_nonzero(dense_weight6)
non_zero_count7 = torch.count_nonzero(dense_weight7)
non_zero_count8 = torch.count_nonzero(dense_weight8)
non_zero_count9 = torch.count_nonzero(dense_weight9)
non_zero_count10 = torch.count_nonzero(dense_weight10)
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count1}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count2}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count3}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count4}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count5}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count6}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count7}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count8}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count9}")
print(f"å‰ªæåç¨€ç–çŸ©é˜µçš„éé›¶å…ƒç´ æ•°é‡: {non_zero_count10}")


# å°†æƒé‡è½¬æ¢ä¸ºç¨€ç–æ ¼å¼ (COO æ ¼å¼)
sparse_weight1 = dense_weight1.to_sparse()
print(f"sparse_weight1ï¼š{sparse_weight1}")

sparse_values_size1 = sparse_weight1._values().nelement() * sparse_weight1._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size1 = sparse_weight1._indices().nelement() * sparse_weight1._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size1 = sparse_values_size1 + sparse_indices_size1

sparse_weight2 = dense_weight2.to_sparse()
sparse_values_size2 = sparse_weight2._values().nelement() * sparse_weight2._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size2 = sparse_weight2._indices().nelement() * sparse_weight2._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size2 = sparse_values_size2 + sparse_indices_size2
print(f"sparse_weight2ï¼š{sparse_weight2}")

sparse_weight3 = dense_weight3.to_sparse()
sparse_values_size3 = sparse_weight3._values().nelement() * sparse_weight3._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size3 = sparse_weight3._indices().nelement() * sparse_weight3._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
print(f"sparse_weight3ï¼š{sparse_weight3}")
print(f"sparse_weight3._indicesï¼š{sparse_weight3._indices()}")


print(sparse_values_size3)
print(sparse_indices_size3)


sparse_total_size3 = sparse_values_size3 + sparse_indices_size3

sparse_weight4 = dense_weight4.to_sparse()
sparse_values_size4 = sparse_weight4._values().nelement() * sparse_weight4._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size4 = sparse_weight4._indices().nelement() * sparse_weight4._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size4 = sparse_values_size4 + sparse_indices_size4

sparse_weight5 = dense_weight5.to_sparse()
sparse_values_size5 = sparse_weight5._values().nelement() * sparse_weight5._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size5 = sparse_weight5._indices().nelement() * sparse_weight5._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size5 = sparse_values_size5 + sparse_indices_size5

sparse_weight6 = dense_weight6.to_sparse()
sparse_values_size6 = sparse_weight6._values().nelement() * sparse_weight6._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size6 = sparse_weight6._indices().nelement() * sparse_weight6._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size6 = sparse_values_size6 + sparse_indices_size6

sparse_weight7 = dense_weight7.to_sparse()
sparse_values_size7 = sparse_weight7._values().nelement() * sparse_weight7._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size7 = sparse_weight7._indices().nelement() * sparse_weight7._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size7 = sparse_values_size7 + sparse_indices_size7

sparse_weight8 = dense_weight8.to_sparse()
sparse_values_size8 = sparse_weight8._values().nelement() * sparse_weight8._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size8 = sparse_weight8._indices().nelement() * sparse_weight8._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size8 = sparse_values_size8 + sparse_indices_size8

sparse_weight9 = dense_weight9.to_sparse()
sparse_values_size9 = sparse_weight9._values().nelement() * sparse_weight9._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size9 = sparse_weight9._indices().nelement() * sparse_weight9._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size9 = sparse_values_size9 + sparse_indices_size9

sparse_weight10 = dense_weight10.to_sparse()
sparse_values_size10 = sparse_weight10._values().nelement() * sparse_weight10._values().element_size()  # éé›¶å€¼çš„å­˜å‚¨ç©ºé—´
sparse_indices_size10 = sparse_weight10._indices().nelement() * sparse_weight10._indices().element_size()  # éé›¶å€¼çš„ç´¢å¼•çš„å­˜å‚¨ç©ºé—´
sparse_total_size10 = sparse_values_size10 + sparse_indices_size10

sparse_total_size_all = sparse_total_size1 + sparse_total_size2 + sparse_total_size3 + sparse_total_size4 + sparse_total_size5 + sparse_total_size6 + sparse_total_size7 + sparse_total_size8 + sparse_total_size9 + sparse_total_size10

print(f"ç¨€ç–çŸ©é˜µå ç”¨å­˜å‚¨ç©ºé—´: {sparse_total_size_all / (1024 * 1024):.2f} MB")
